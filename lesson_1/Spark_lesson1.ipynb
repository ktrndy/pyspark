{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EAL7YbIqGFr"
      },
      "source": [
        "**Занятие первое**\n",
        "\n",
        "Начнем с простого. Многие знают что такое map и reduce операции, но все же для закрпеления мы их тут реализуем. Ах да, не забудем и про shuffle. Делать все будем на упрощенной задаче с word count для ознакомления с самим подходом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DBUYlacS6nb"
      },
      "source": [
        "На самом деле мы рассмптрим все в упрощенном виде, но это даст нам понимание, как можно через hadoop streaming, например, писать самописные map и reduce операции"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHxuTfZ1TKc9"
      },
      "source": [
        "! mapred streaming \\\n",
        "  -input /wiki/sample.jsonl \\\n",
        "  -output /word-count \\\n",
        "  -mapper \"/opt/conda/bin/python3.6 mapper.py\" \\\n",
        "  -reducer \"/opt/conda/bin/python3.6 reducer.py\" \\\n",
        "  -file mapper.py \\\n",
        "  -file reducer.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe2aSFz_Tgqv"
      },
      "source": [
        "Выше mapper.py и reducer.py это программы, которые выполняют одноименные операции нам потоком информации из jsonl файла, записывая ответ в файл word-count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hGAAKrdu5d-"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPXzd-YMtqcO"
      },
      "source": [
        "Давайте загрузим файл с текстом и посмотрим на него"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKUCkYpBp9Lt"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/PySpark/spark_text.txt', 'rb') as f:\n",
        "    data = f.readlines()\n",
        "data = [text.decode() for text in data if text.decode() != '\\r\\n']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CywPTchftnqK"
      },
      "outputs": [],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wRwGdoJ5pQs"
      },
      "outputs": [],
      "source": [
        "data[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydjOU0HLwCZq"
      },
      "source": [
        "Как бы мы сделали..\n",
        "Надо немного почистить слова, а также сделать все в парадигме MapReduce. Понятно, что можно все написать проще, но мы ведь хотим понять, как это работает=)\n",
        "\n",
        "Загрузим стоп слова, очистим от них текст, приведем к нижнему регистру, всем раздадим ключи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-zIUslxxtyQ"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "stop_words = set(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOXxYSKI2EfQ"
      },
      "outputs": [],
      "source": [
        "stop_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDK6W4MUewdv"
      },
      "source": [
        "пунктуацию тоже полезно бы удалить"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhrSCeUJ2MKZ"
      },
      "outputs": [],
      "source": [
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0AjYtsiv9tc"
      },
      "outputs": [],
      "source": [
        "def mapper_text(text):\n",
        "    clean_text = re.sub(rf\"[{string.punctuation}]\", \"\", text)\n",
        "    words = nltk.word_tokenize(clean_text)\n",
        "    words_with_value = [(word.lower(), 1) for word in words\n",
        "                        if word not in stop_words]\n",
        "    words_with_value = sorted(words_with_value, key=lambda x:x[0])\n",
        "    return words_with_value\n",
        "\n",
        "def create_chunks(shuffled_data):\n",
        "    result = {}\n",
        "    for idx, data in shuffled_data:\n",
        "        if idx in result:\n",
        "            result[idx].append(data)\n",
        "        else:\n",
        "            result[idx] = [data]\n",
        "    return list(result.items())\n",
        "\n",
        "def shuffle_text(mapper_result, n_nodes=5):\n",
        "    shuffled_data = []\n",
        "    for key, value in mapper_result:\n",
        "        shuffled_data.append((hash(key)%n_nodes, (key, value)))\n",
        "    shuffled_data = sorted(shuffled_data, key=lambda x: x[0])\n",
        "    chunks = create_chunks(shuffled_data)\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# на самом деле для reduce в жизни пишут иначе..не зря мы сортируем внутри map\n",
        "#данные по ключам. Это нужно для избавления от этапа проверки ключа и поиска\n",
        "def reduce_text(values_to_reduce):\n",
        "    result = {}\n",
        "    for key, value in values_to_reduce:\n",
        "        if key in result:\n",
        "            result[key] += 1\n",
        "        else:\n",
        "            result[key] = 1\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7qztZ0ijcqf"
      },
      "source": [
        "Проверим, что все работает\n",
        "\n",
        "Сначала map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "133g98tQMT8I"
      },
      "outputs": [],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpqqPnNRhCXp"
      },
      "outputs": [],
      "source": [
        "map_stage = mapper_text(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hiOXuxSsDno"
      },
      "outputs": [],
      "source": [
        "map_stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoOq2kxGl4FM"
      },
      "source": [
        "shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLyQcJ7Xjmll"
      },
      "outputs": [],
      "source": [
        "shuffle_stage = shuffle_text(map_stage, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ig2vthBFsNTm"
      },
      "outputs": [],
      "source": [
        "shuffle_stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rqyNgzpl8q1"
      },
      "source": [
        "reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJed4iQsll9i"
      },
      "outputs": [],
      "source": [
        "reduce_text(shuffle_stage[4][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOuqRbx5srNh"
      },
      "source": [
        "Итак, осталось все рассчитать параллельно и собрать результаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "v3ogNEUhtvkD"
      },
      "outputs": [],
      "source": [
        "n_nodes = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rA9awfQ4RSo"
      },
      "source": [
        "Обернем в 1 функциию для удобства map и shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TItZtKEF4Qiu"
      },
      "outputs": [],
      "source": [
        "def map_shuffle(text, n_nodes):\n",
        "    map_result = mapper_text(text)\n",
        "    shuffle_result = shuffle_text(map_result, n_nodes)\n",
        "    return shuffle_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WOywHRItFWD"
      },
      "outputs": [],
      "source": [
        "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=5) as parallel:\n",
        "    res = parallel(delayed(map_shuffle)(df, n_nodes) for df in data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIfatYoXMjPW"
      },
      "outputs": [],
      "source": [
        "len(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EgpGGu9MknD"
      },
      "outputs": [],
      "source": [
        "res[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvAYM5vA9K8N"
      },
      "source": [
        "Сделаем что-то вроде перессылки, собирая все в словари и заодно посмотрим на сколько равномерно распределлиись наши слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kTLnBO24013"
      },
      "outputs": [],
      "source": [
        "shuffle_stage = {i:[] for i in range(5)}\n",
        "for values in res:\n",
        "    values = dict(values)\n",
        "    for key in values.keys():\n",
        "        shuffle_stage[key].extend(values[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9sAjyP46kUE"
      },
      "outputs": [],
      "source": [
        "for key in shuffle_stage.keys():\n",
        "    print(f'{key}: number of words = {len(shuffle_stage[key])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVEA-LZG9eEv"
      },
      "source": [
        "И последний этап - нужно сделать reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i95b8FbDboX"
      },
      "outputs": [],
      "source": [
        "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=5) as parallel:\n",
        "    res = parallel(delayed(reduce_text)(shuffle_stage[key]) for key in shuffle_stage.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkGsGeKE7FeS"
      },
      "outputs": [],
      "source": [
        "len(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8on05jYEMxUp"
      },
      "outputs": [],
      "source": [
        "res[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZsgvg9oEVwt"
      },
      "source": [
        "Собираем результат"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVKdO8eAD24r"
      },
      "outputs": [],
      "source": [
        "result = {}\n",
        "for partition in res:\n",
        "    for key in partition.keys():\n",
        "        if key in result:\n",
        "            result[key] += partition[key]\n",
        "        else:\n",
        "            result[key] = partition[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUTsOJf7EtW1"
      },
      "outputs": [],
      "source": [
        "sorted(result.items(), key=lambda x: x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OViND9SFFTOd"
      },
      "source": [
        "Да, было бы проще все сделать иным кодом и в один проход, но целью было разобрать, как все это примерно работает под капотом на больших данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhK08F7hFjv_"
      },
      "source": [
        "**Домашнее задание**\n",
        "\n",
        "Посчитать количество рейтингов больше 4 для каждого фильма и вывести фильмы в порядке убывания количества этих оценок"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIK772EkXm36",
        "outputId": "03345c27-50ba-4511-f2e3-d634c8fcd91e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sPx9_0-wFlK-"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/My Drive/Colab_Notebooks/PySpark/user_ratedmovies.dat', 'rb') as f:\n",
        "    data = f.readlines()\n",
        "headers = data[0].decode().split('\\t')[:3]\n",
        "data = [row.decode().split('\\t')[:3] for row in data[1:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8yWQm0zJegy",
        "outputId": "28a6244d-f268-4378-b24f-dea4b8466333"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['userID', 'movieID', 'rating']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "headers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgDpQdAeRG5e",
        "outputId": "4fd471de-1001-403e-a963-b78c93c6e7fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['75', '3', '1']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln4GFhQZH5tM",
        "outputId": "36ec0ebb-9ad5-4c1e-ca8f-d4f6e6781fe3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "855598"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzkqhk9MRL8P"
      },
      "source": [
        "Пишем map, shiffle и reduce + параллелим вычисления. Лучше задавать batch_size при распараллеливании, либо даже заранее все разбить на батчи, будет быстрее\n",
        "\n",
        "Также посмотрите на то, нет ли перекоса в данных после shuffle, можете попробовать использовать остаток от деления не простого hash, а ввести какую-то функию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_1aUiwrJRK3W"
      },
      "outputs": [],
      "source": [
        "def map_rating(row):\n",
        "    if float(row[2]) > 4:\n",
        "        return row[1], 1\n",
        "    else:\n",
        "        return row[1], 0\n",
        "\n",
        "def create_chunks(shuffled_data):\n",
        "    result = {}\n",
        "    for idx, data in shuffled_data:\n",
        "        if idx in result:\n",
        "            result[idx].append(data)\n",
        "        else:\n",
        "            result[idx] = [data]\n",
        "    return list(result.items())\n",
        "\n",
        "def shuffle_rating(mapper_result, n_nodes=5):\n",
        "    shuffled_data = []\n",
        "    for key, value in mapper_result:\n",
        "        shuffled_data.append((hash(key)%n_nodes, (key, value)))\n",
        "    shuffled_data = sorted(shuffled_data, key=lambda x: x[0])\n",
        "    chunks = create_chunks(shuffled_data)\n",
        "    return chunks\n",
        "\n",
        "def reduce_rating(values_to_reduce):\n",
        "    result = {}\n",
        "    for key, value in values_to_reduce:\n",
        "        if key in result:\n",
        "            result[key] += value\n",
        "        else:\n",
        "            result[key] = value\n",
        "    return result\n",
        "\n",
        "def map_shuffle(batch, n_nodes):\n",
        "    map_result = list()\n",
        "    for row in batch:\n",
        "        map_result.append(map_rating(row))\n",
        "    shuffle_result = shuffle_rating(map_result, n_nodes)\n",
        "    return shuffle_result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_nodes = 5\n",
        "\n",
        "n_batches = 100\n",
        "batch_size = len(data)//n_batches\n",
        "\n",
        "data_batches = [data[i*batch_size:(i+1)*batch_size] for i in range(n_batches+1)]"
      ],
      "metadata": {
        "id": "17bQrgCS2Obi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KJdLsomDRyS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42f0d84-c1f9-4aa2-f381-618d4b5e864d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
            "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:    3.8s\n",
            "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    4.7s\n",
            "[Parallel(n_jobs=5)]: Done  51 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=5)]: Done  62 tasks      | elapsed:    5.8s\n",
            "[Parallel(n_jobs=5)]: Done  75 tasks      | elapsed:    6.3s\n",
            "[Parallel(n_jobs=5)]: Done  88 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=5)]: Done 101 out of 101 | elapsed:    7.3s finished\n"
          ]
        }
      ],
      "source": [
        "with Parallel(n_jobs=n_nodes, verbose=10) as parallel:\n",
        "    res = parallel(delayed(map_shuffle)(batch, n_nodes) for batch in data_batches)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yIxt5plYTdu",
        "outputId": "97cef9f8-6515-41bb-e2d2-168e70a781cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res[0][0][1][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S7HFHnJYDse",
        "outputId": "211f8e72-b165-4342-b7f4-9381571297a0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1036', 0),\n",
              " ('1127', 0),\n",
              " ('1233', 0),\n",
              " ('1304', 0),\n",
              " ('1485', 0),\n",
              " ('1917', 0),\n",
              " ('2640', 0),\n",
              " ('2959', 1),\n",
              " ('3258', 0),\n",
              " ('5952', 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle_stage = {i:[] for i in range(n_nodes)}\n",
        "for values in res:\n",
        "    values = dict(values)\n",
        "    for key in values.keys():\n",
        "        shuffle_stage[key].extend(values[key])"
      ],
      "metadata": {
        "id": "C2EhM9_tPx5I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle_stage[0][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLpaGivlYpT9",
        "outputId": "0e7d943e-b860-43ed-c9c0-1986e140af77"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1036', 0),\n",
              " ('1127', 0),\n",
              " ('1233', 0),\n",
              " ('1304', 0),\n",
              " ('1485', 0),\n",
              " ('1917', 0),\n",
              " ('2640', 0),\n",
              " ('2959', 1),\n",
              " ('3258', 0),\n",
              " ('5952', 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in shuffle_stage.keys():\n",
        "    print(f'{key}: number of films = {len(shuffle_stage[key])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXY1aUMuQEmA",
        "outputId": "f6732dd2-6065-4c4e-e4c3-063527d91819"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: number of films = 168354\n",
            "1: number of films = 177666\n",
            "2: number of films = 168259\n",
            "3: number of films = 172311\n",
            "4: number of films = 169008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SmKhm2eeRyVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e89069-c7bf-4df0-e8fa-7074ddeb727b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
            "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    1.0s remaining:    1.5s\n",
            "[Parallel(n_jobs=5)]: Done   3 out of   5 | elapsed:    1.0s remaining:    0.7s\n",
            "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    1.5s finished\n"
          ]
        }
      ],
      "source": [
        "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=5) as parallel:\n",
        "    res = parallel(delayed(reduce_rating)(shuffle_stage[key]) for key in shuffle_stage.keys())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(res[0].items())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRESihyUY0RR",
        "outputId": "bb15c88f-5ff6-4b02-b42e-8ec8db5e5bba"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1036', 61),\n",
              " ('1127', 38),\n",
              " ('1233', 80),\n",
              " ('1304', 29),\n",
              " ('1485', 8),\n",
              " ('1917', 31),\n",
              " ('2640', 23),\n",
              " ('2959', 169),\n",
              " ('3258', 2),\n",
              " ('5952', 125)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed0nAHrDSMcX"
      },
      "source": [
        "После reduce все можно собрать в одном цикле, считаем, что данные переслали после на 1 машину и агрегируем"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = {}\n",
        "for partition in res:\n",
        "    for key in partition.keys():\n",
        "        if key in result:\n",
        "            result[key] += partition[key]\n",
        "        else:\n",
        "            result[key] = partition[key]"
      ],
      "metadata": {
        "id": "M83odRaOzCz_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
        "result[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKC6hUISRXJL",
        "outputId": "5faf8ba4-8a3e-4e61-b50c-254e29e74f27"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2571', 900),\n",
              " ('318', 887),\n",
              " ('296', 878),\n",
              " ('2959', 828),\n",
              " ('4993', 756),\n",
              " ('7153', 719),\n",
              " ('5952', 697),\n",
              " ('858', 690),\n",
              " ('50', 688),\n",
              " ('2858', 680)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# наивная проверка\n",
        "\n",
        "films = dict()\n",
        "for row in data:\n",
        "  if row[1] not in films:\n",
        "    films[row[1]] = int(float(row[2]) > 4)\n",
        "  else:\n",
        "    films[row[1]] += int(float(row[2]) > 4)\n",
        "\n",
        "films = sorted(films.items(), key=lambda x: x[1], reverse=True)\n",
        "films[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm6yE7wWR68c",
        "outputId": "8f5903f0-ec04-4e48-b51b-51668173287f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2571', 900),\n",
              " ('318', 887),\n",
              " ('296', 878),\n",
              " ('2959', 828),\n",
              " ('4993', 756),\n",
              " ('7153', 719),\n",
              " ('5952', 697),\n",
              " ('858', 690),\n",
              " ('50', 688),\n",
              " ('2858', 680)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}